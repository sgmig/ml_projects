{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Convolutional NN it for facial keypoints recognition\n",
    "\n",
    "Here I will build a convolutional neural network, and train it for the task of facial keypoints recognition. The data are obtained from Kaggle: **LINK**, and consists of **info**.\n",
    "\n",
    "I will build the CNN using tensorflow **link**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading source data.\n",
    "training_data = pd.read_csv('training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Images are stored as string. We convert them to a np array. \n",
    "\n",
    "images = training_data['Image'].apply(lambda str_pic: np.array([int(px) for px in str_pic.split()]))\n",
    "images = np.vstack([images.iloc[i] for i in range(len(images))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating keypoints dataframe. \n",
    "keypoints = training_data.drop('Image', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation: Including reflected pictures into the dataset\n",
    "\n",
    "In order to increase our dataset I will reflect all images left to right, and add them as different images.\n",
    "\n",
    "This implies flipping the images, and reflecting all x-coordinates of the keypoints such that $x_{reflected} = 95 - x_{old}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building an array of reflected images.\n",
    "flipped_ims = np.zeros(images.shape)\n",
    "for j in range(images.shape[0]):\n",
    "    for i in range(96):\n",
    "        flipped_ims[j,i*96:(i+1)*96] = np.flip(images[j,i*96:(i+1)*96])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the reflected images to our images array. \n",
    "# RUN THIS CELL ONLY ONCE. \n",
    "images = np.vstack((images, flipped_ims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the keypoints. I need to switch left and right features, \n",
    "# and reflect the x coordinates by x --> 95-x (95 is the last coordinate of the picture. )\n",
    "\n",
    "reflected_keypoints = pd.DataFrame(columns = keypoints.columns)\n",
    "\n",
    "# We look for the correspoding columns by switching 'left' <--> 'right'.\n",
    "for colname in reflected_keypoints.columns:\n",
    "    if 'left' in colname:\n",
    "        reference_col = colname.replace('left', 'right')\n",
    "    elif 'right' in colname:\n",
    "        reference_col = colname.replace('right','left')\n",
    "    else:\n",
    "        reference_col = colname\n",
    "        \n",
    "    # Assigning values and reflecting x coordinates\n",
    "    # reflected_keypoints[colname] = keypoints[reference_col].apply(lambda x: 95-x if colname[-1]=='x' else x)\n",
    "    # the one-line version is fine but I think separating is more readable.\n",
    "    \n",
    "    reflected_keypoints[colname] = keypoints[reference_col]\n",
    "    if colname[-1] == 'x':\n",
    "        reflected_keypoints[colname] = reflected_keypoints[colname].apply(lambda x: 95-x)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding reflected keypoints to the original keypoints. \n",
    "# RUN THIS CELL ONLY ONCE.\n",
    "keypoints = pd.concat([keypoints,reflected_keypoints], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a train_test_split in order to have a cross validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_cv, keypoints_train, keypoints_cv = train_test_split(images, keypoints, \n",
    "                                                                test_size=500, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the mean poistion the RMSE on the cv set is:  3.8490320110627083\n"
     ]
    }
   ],
   "source": [
    "# BASELINE\n",
    "# As a guide, we compute the error on the cv set obtained by using the mean position of\n",
    "# each keypoint.\n",
    "\n",
    "mean_keypoints = keypoints_train.mean()\n",
    "baseline_rmse = np.sqrt(((keypoints_cv - mean_keypoints)**2).mean().mean())\n",
    "\n",
    "print('Using the mean poistion the RMSE on the cv set is: ', baseline_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good estimation should improve on this result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Define a function for taking random batches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(X, labels, batch_size):\n",
    "    \"\"\" A function for generating training batches. \n",
    "    X = Collection of examples.\n",
    "    labels = True labels. \n",
    "    batch_size = Number of elements to be randomly selected. \"\"\"\n",
    "    sample_indices = np.random.choice(range(len(X)), size = batch_size, \n",
    "                                      replace = False)\n",
    "    \n",
    "    images = X[sample_indices]\n",
    "    keypoints = labels.iloc[sample_indices]\n",
    "        \n",
    "    return images, keypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the CNN\n",
    "\n",
    "I will start by using the same architechture I used in the course.For the moment I will use train_test_split to test my network a bit. Eventually this wont be necessary, as the dataset provides a separate test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrappers of tensorflow methods. This functions will help make\n",
    "# the construction of the network more straightforward. \n",
    "\n",
    "def init_weights(shape):\n",
    "    #init_random_dist = tf.initializers.random_normal(stddev=0.1)\n",
    "    init_random_dist = tf.initializers.he_normal()\n",
    "    return tf.get_variable('weights', shape=shape ,initializer= init_random_dist)\n",
    "\n",
    "def init_bias(shape):\n",
    "    #init_bias_vals = tf.random_uniform(shape=shape)\n",
    "    init_bias_vals = tf.initializers.random_uniform()\n",
    "    return tf.get_variable('bias', shape = shape ,initializer= init_bias_vals)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2by2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def convolutional_layer(input_x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W) + b)\n",
    "\n",
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b\n",
    "\n",
    "def output_act_function(input_layer):\n",
    "    factor = tf.constant(96, dtype = tf.float32)\n",
    "    return tf.multiply(factor, tf.nn.sigmoid(input_layer))\n",
    "\n",
    "def sigmoid_layer(input_layer, size, max_val):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    factor = tf.constant(max_val, dtype = tf.float32)\n",
    "    return tf.multiply(factor, tf.nn.sigmoid(tf.matmul(input_layer, W) + b))\n",
    "    \n",
    "\n",
    "def new_bn_layer(input_x, training, decay = 0.999):\n",
    "    \"\"\" Wrapper function for tf.contrib.layers.batch_norm \"\"\"\n",
    "    \n",
    "    return tf.contrib.layers.batch_norm(input_x, decay = decay, is_training = training  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLACEHOLDERS\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 9216])\n",
    "keypoints_true = tf.placeholder(tf.float32, [None, 30])\n",
    "lr = tf.placeholder(tf.float32)\n",
    "#training = tf.placeholder(tf.bool)\n",
    "#L = tf.placeholder(tf.float32)\n",
    "drop_rate = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_images = tf.image.per_image_standardization(tf.reshape(x, [-1,96,96,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAYERS\n",
    "\n",
    "with tf.variable_scope('Convo1'):\n",
    "    convo1 = convolutional_layer(x_images, [6,6,1,32]) # 6 x 6 filter, 1 channel in, 32 channels out. SAME padding.\n",
    "                                            # so output images are also 96 x 96. \n",
    "\n",
    "    convo1_pool = tf.nn.max_pool(convo1, ksize=[1, 4, 4, 1],\n",
    "                          strides=[1, 4, 4, 1], padding='SAME')   #output of 24 x 24 x 32\n",
    "        \n",
    "with tf.variable_scope('Convo2'):    \n",
    "    convo2 = convolutional_layer(convo1_pool, [2,2,32,64]) # 4x4 filter, 64 outputs. SAME padding.\n",
    "\n",
    "    convo2_pool = max_pool_2by2(convo2) # 12 x 12 x64\n",
    "    \n",
    "            \n",
    "with tf.variable_scope('Convo3'):\n",
    "    convo3 = convolutional_layer(convo2_pool, [2,2,64,128]) # 2x2 filter, 128 outputs. SAME padding.\n",
    "\n",
    "    convo3_pool = max_pool_2by2(convo3) # 6 x 6 x 128\n",
    "\n",
    "    convo3_flat = tf.reshape(convo3_pool,[-1,6*6*128])\n",
    "    \n",
    "with tf.variable_scope('Full_one'):\n",
    "    \n",
    "    full_layer_one = tf.nn.relu(normal_full_layer(convo3_flat,1024))\n",
    "    \n",
    "        \n",
    "# DROPOUT \n",
    "\n",
    "full_one_dropout = tf.nn.dropout(full_layer_one, rate = drop_rate)\n",
    "\n",
    "# OUTPUT LAYER\n",
    "with tf.variable_scope('Output'):\n",
    "    \n",
    "    keypoints_pred = normal_full_layer(full_one_dropout,30)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOSS FUNCTION\n",
    "with tf.variable_scope('Loss'):\n",
    "    masked_loss = tf.reduce_mean(tf.square(\n",
    "        tf.boolean_mask(keypoints_pred - keypoints_true, tf.is_finite(keypoints_true) ) ) ) \n",
    "                                 \n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "\n",
    "        train = optimizer.minimize(masked_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZER\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-443f00428229>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         _ , train_loss= sess.run([train, masked_loss], \n\u001b[1;32m     22\u001b[0m                              feed_dict={x: x_batch, keypoints_true: keypoints_batch,\n\u001b[0;32m---> 23\u001b[0;31m                                         lr:0.0005, drop_rate:0})\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_steps = 5000\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    #saver.restore(sess, \"./saved_models/keypoints_cnn_\" + str(counter) )\n",
    "    #saver.restore(sess, \"./saved_models/keypoints_3_lay_cnn_3\")\n",
    "    train_losses = []\n",
    "    cv_losses = []\n",
    "    \n",
    "    \n",
    "    for iteration in range(num_steps+1):\n",
    "        \n",
    "        x_batch, keypoints_batch = next_batch(x_train, keypoints_train, 32)\n",
    "        \n",
    "        \n",
    "        # Uncomment for BN\n",
    "        _ , train_loss= sess.run([train, masked_loss], \n",
    "                             feed_dict={x: x_batch, keypoints_true: keypoints_batch,\n",
    "                                        lr:0.0005, drop_rate:0})\n",
    "        \n",
    "        if iteration%100 == 0:\n",
    "            \n",
    "            cv_loss = sess.run(masked_loss,\n",
    "                               feed_dict={x:x_cv, keypoints_true:keypoints_cv, drop_rate:0})\n",
    "            \n",
    "            train_losses.append(np.sqrt(train_loss))\n",
    "            cv_losses.append(np.sqrt(cv_loss))\n",
    "                        \n",
    "            # Showing output for tracking progress.\n",
    "            print('=======================================')\n",
    "            print('Currently on step {}'.format(iteration))\n",
    "            print('Train MSE: ', train_losses[-1], '\\n')\n",
    "            print('CV MSE:', cv_losses[-1], '\\n')\n",
    "            \n",
    "            ax.cla()\n",
    "            ax.plot(train_losses[1:], 'r', label = 'Training error')\n",
    "            ax.plot(cv_losses[1:], 'g', label = 'Validation error')\n",
    "            ax.legend()\n",
    "            display(fig)\n",
    "            \n",
    "            print('=======================================')\n",
    "            print('train_losses = ', train_losses, '\\n')\n",
    "            print('cv_losses = ', cv_losses)\n",
    "            \n",
    "            clear_output(wait = True)\n",
    "    \n",
    "    # printing final results\n",
    "    \n",
    "    print('=======================================')\n",
    "    print('Currently on step {}'.format(iteration))\n",
    "    print('Train MSE: ', train_losses[-1], '\\n')\n",
    "    print('CV MSE:',  cv_losses[-1], '\\n')\n",
    "\n",
    "    ax.cla()\n",
    "    ax.plot(train_losses[1:], 'r', label = 'Training error')\n",
    "    ax.plot(cv_losses[1:], 'g', label = 'Validation error')\n",
    "    ax.legend()\n",
    "    \n",
    "            \n",
    "    print('=======================================')\n",
    "    print('train_losses = ', train_losses, '\\n')\n",
    "    print('cv_losses = ', cv_losses)\n",
    "            \n",
    "    saver.save(sess, \"./saved_models/keypoints_cnn_\" + str(counter) )\n",
    "    #saver.save(sess, \"./saved_models/keypoints_cnn_1\"  )\n",
    "    #counter +=1\n",
    "    #print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.6651897"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_losses[-15:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[29.201872,\n",
       " 4.8370113,\n",
       " 3.8364406,\n",
       " 3.4786668,\n",
       " 3.765306,\n",
       " 3.5623374,\n",
       " 3.2585316,\n",
       " 3.418986,\n",
       " 3.2185562,\n",
       " 3.134268,\n",
       " 3.1227243,\n",
       " 3.1475754]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions for the cv set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Use your Saver instance to restore your saved rnn time series model\n",
    "    saver.restore(sess, \"./saved_models/keypoints_3_lay_cnn_\" + str(counter))\n",
    "\n",
    "    # Create a numpy array for your genreative seed from the last 12 months of the \n",
    "    # training set data. Hint: Just use tail(12) and then pass it to an np.array\n",
    "        \n",
    "    predictions = sess.run(keypoints_pred, feed_dict= {x:x_cv, drop_rate:0 })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unravel_index( np.argmax(predictions), predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[73,29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 3\n",
    "fig, axes = plt.subplots(grid_size, grid_size, gridspec_kw = dict(hspace = .05, wspace = .05), \n",
    "                         figsize=(10,10))\n",
    "\n",
    "selection = np.random.choice(range(len(x_cv)), size = grid_size**2, )\n",
    "\n",
    "mean_x_points = [keypoints_mean[j] for j in range(0,30,2)]\n",
    "mean_y_points = [keypoints_mean[j+1] for j in range(0,30,2)]\n",
    "\n",
    "for i, ax in zip(selection, axes.flat):\n",
    "\n",
    "    ax.axis('off')\n",
    "    # Plotting the faces\n",
    "    ax.imshow(x_cv[i].reshape((96,96)),cmap='gist_gray')\n",
    "\n",
    " # Obtaining keypoints positions. x and y coordinates are even and odd indices respectively. \n",
    "    x_points = [predictions[i][j] for j in range(0,30,2)]\n",
    "    y_points = [predictions[i][j+1] for j in range(0,30,2)]\n",
    "      \n",
    "    #plotting predicted keypoints\n",
    "    ax.plot(x_points, y_points, 'ro', markerfacecolor = 'none')    \n",
    "  \n",
    " # Plotting true keypoints\n",
    "    \n",
    "    x_true = [keypoints_cv.iloc[i][j] for j in range(0,30,2)]\n",
    "    y_true = [keypoints_cv.iloc[i][j+1] for j in range(0,30,2)]\n",
    "    \n",
    "    ax.plot(x_true, y_true, 'b*', markerfacecolor = 'none')    \n",
    "    \n",
    " # Including mean keypoints\n",
    "       \n",
    "    #ax.plot(mean_x_points, mean_y_points, 'b+', markerfacecolor = 'none')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = test_data['Image'].apply(lambda str_pic: np.array([int(px) for px in str_pic.split()]))\n",
    "\n",
    "test_images = np.vstack([test_images.iloc[i] for i in range(len(test_images))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Use your Saver instance to restore your saved rnn time series model\n",
    "    saver.restore(sess, \"./saved_models/keypoints_3_lay_cnn_\" + str(counter))\n",
    "    #saver.restore(sess, \"./saved_models/keypoints_3_lay_cnn_3\" )\n",
    "\n",
    "    # Create a numpy array for your genreative seed from the last 12 months of the \n",
    "    # training set data. Hint: Just use tail(12) and then pass it to an np.array\n",
    "        \n",
    "    predictions = sess.run(keypoints_pred, feed_dict= {x:test_images, drop_rate:0 })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 2\n",
    "fig, axes = plt.subplots(grid_size, grid_size, gridspec_kw = dict(hspace = .05, wspace = .05), \n",
    "                         figsize=(10,10))\n",
    "\n",
    "#selection = np.random.choice(range(len(test_images)), size = grid_size**2 )\n",
    "selection = [131, 159, 491, 525]\n",
    "for i, ax in zip(selection, axes.flat):\n",
    "\n",
    "    ax.axis('off')\n",
    "    # Plotting the faces\n",
    "    ax.imshow(test_images[i].reshape((96,96)),cmap='gist_gray')\n",
    "\n",
    " # Obtaining keypoints positions. x and y coordinates are even and odd indices respectively. \n",
    "    x_points = [predictions[i][j] for j in range(0,30,2)]\n",
    "    y_points = [predictions[i][j+1] for j in range(0,30,2)]\n",
    "      \n",
    "    #plotting predicted keypoints\n",
    "    ax.plot(x_points, y_points, 'ro', markerfacecolor = 'none')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a dataframe with predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_keypoints = pd.DataFrame(data = predictions, columns = keypoints.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_keypoints[(predicted_keypoints>96).any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_keypoints.to_csv('full_test_predictions_002.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the lookup table to make a submission file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_table = pd.read_csv('IdLookupTable.csv', header = 0, index_col = 'RowId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "locations_list = []\n",
    "for i in lookup_table.iterrows():\n",
    "    position = predicted_keypoints.iloc[i[1]['ImageId']-1][i[1]['FeatureName']]\n",
    "    locations_list.append(position)\n",
    "len(locations_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty dataframe for testing submission\n",
    "Submission_df = pd.DataFrame(columns = ['Location'], index = lookup_table.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission_df['Location'] = locations_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission_df.to_csv('submission_002.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
