{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Convolutional NN it for facial keypoints recognition\n",
    "\n",
    "Here I will build a convolutional neural network, and train it for the task of facial keypoints recognition. The data are obtained from Kaggle: **LINK**, and consists of **info**.\n",
    "\n",
    "I will build the CNN using tensorflow **link**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_full = pd.read_csv('training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = training_data_full['Image'].apply(lambda str_pic: np.array([int(px) for px in str_pic.split()]))\n",
    "\n",
    "images = np.vstack([images.iloc[i] for i in range(len(images))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints = training_data_full.drop('Image', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_cv, keypoints_train, keypoints_cv = train_test_split(images, keypoints, \n",
    "                                                                test_size=100, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(X, labels, batch_size):\n",
    "    \n",
    "    sample_indices = np.random.choice(range(len(X)), size = batch_size, \n",
    "                                      replace = False)\n",
    "    \n",
    "    images = X[sample_indices]\n",
    "    keypoints = labels.iloc[sample_indices]\n",
    "        \n",
    "    return images, keypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the CNN\n",
    "\n",
    "I will start by using the same architechture I used in the course.For the moment I will use train_test_split to test my network a bit. Eventually this wont be necessary, as the dataset provides a separate test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some helping functions.\n",
    "def init_weights(shape):\n",
    "    init_random_dist = tf.random_normal(shape, stddev=0.1) # Why this stddev?\n",
    "    return tf.Variable(init_random_dist)\n",
    "\n",
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.random_uniform(shape=shape)\n",
    "    return tf.Variable(init_bias_vals)\n",
    "\n",
    "def init_gamma(shape):\n",
    "    init_gamma_val = tf.constant(1, dtype = tf.float32)\n",
    "    return tf.Variable(init_gamma_val)\n",
    "\n",
    "def init_beta(shape):\n",
    "    init_beta_val = tf.constant(0, dtype = tf.float32)\n",
    "    return tf.Variable(init_beta_val)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2by2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 4, 4, 1],\n",
    "                          strides=[1, 4, 4, 1], padding='SAME')\n",
    "\n",
    "def convolutional_layer(input_x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W) + b)\n",
    "\n",
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b\n",
    "\n",
    "\n",
    "def bn_layer(input_x, is_training, bn_type = 'normal', decay = 0.999):\n",
    "    \n",
    "    \"\"\"Implements batch normalization. \n",
    "    input_x: A Tensor. Is the data to normalize.\n",
    "    is_training: Bool. Indicates whether we are in training o predictino phase. \n",
    "    bn_type: 'normal' or 'convo', indicates over which indeces we take the means. \n",
    "              if 'normal', we use only the first index (batch number).\n",
    "              if 'conv', uses [0,1,2]\n",
    "    decay: float. decay parameter for the running averages. \n",
    "    \"\"\"\n",
    "    \n",
    "    if bn_type == 'normal':\n",
    "        shape = input_x.shape[1:]\n",
    "        axes = [0]\n",
    "    elif bn_type == 'convo':\n",
    "        shape = input_x.shape[-1]\n",
    "        axes = [0,1,2]\n",
    "        \n",
    "    #running mean and variance to be sued for inference.\n",
    "    pop_mean = tf.Variable(tf.zeros(shape), trainable=False) \n",
    "    pop_var = tf.Variable(tf.ones(shape), trainable=False)\n",
    "    \n",
    "    gamma = init_gamma(shape) #in the normalization I am using this is the number of channels. \n",
    "    beta = init_beta(shape)\n",
    "    \n",
    "    batch_mean, batch_var = tf.nn.moments(input_x, axes)  \n",
    "    \n",
    "    def train_phase():\n",
    "        train_mean = tf.assign(pop_mean, pop_mean * decay + batch_mean * (1 - decay))\n",
    "        train_var = tf.assign(pop_var, pop_var * decay + batch_var * (1 - decay))\n",
    "        with tf.control_dependencies([train_mean, train_var]):\n",
    "            return tf.nn.batch_normalization(input_x, batch_mean, batch_var,\n",
    "                                                    offset = beta, scale = gamma,\n",
    "                                                    variance_epsilon=0.0001)\n",
    "    \n",
    "    def infer_phase(): \n",
    "        return tf.nn.batch_normalization(input_x, pop_mean, pop_var, offset = beta, \n",
    "                                  scale = gamma, variance_epsilon=0.0001)\n",
    "    \n",
    "        \n",
    "    return tf.cond(is_training, train_phase, infer_phase)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLACEHOLDERS\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 9216])\n",
    "keypoints_true = tf.placeholder(tf.float32, [None, 30])\n",
    "lr = tf.placeholder(tf.float32)\n",
    "training = tf.placeholder(tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/image_ops_impl.py:1241: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "x_images = tf.image.per_image_standardization(tf.reshape(x, [-1,96,96,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAYERS\n",
    "\n",
    "convo1 = convolutional_layer(x_images, [8,8,1,32]) # 8 x 8 filter, 1 channel in, 32 channels out. SAME padding.\n",
    "                                            # so output images are also 96 x 96. \n",
    "\n",
    "convo1_bn = bn_layer(convo1, training, bn_type = 'normal')    \n",
    "#convo1 = convolutional_layer_with_bn(x_images, [8,8,1,32], is_training = training)\n",
    "convo1_pool = max_pool_2by2(convo1_bn)   #output of 24 x 24 x 32\n",
    "\n",
    "convo2 = convolutional_layer(convo1_pool, [4,4,32,64]) # 4x4 filter, 64 outputs. SAME padding.\n",
    "\n",
    "convo2_bn = bn_layer(convo2, training, bn_type = 'normal')    \n",
    "#convo2 = convolutional_layer_with_bn(convo1_pool, [4,4,32,64], is_training = training) # 4x4 filter, 64 outputs. SAME padding.\n",
    "convo2_pool = max_pool_2by2(convo2_bn) # 6 x 6 x 64\n",
    "\n",
    "convo2_flat = tf.reshape(convo2_pool,[-1,6*6*64])\n",
    "\n",
    "convo2_flat_bn = bn_layer(convo2_flat, training, bn_type='normal')\n",
    "\n",
    "full_layer_one = tf.nn.relu(normal_full_layer(convo2_flat_bn,1024))\n",
    "\n",
    "#full_layer_one = tf.nn.relu(normal_full_layer_with_bn(convo2_flat,1024, is_training = training))\n",
    "\n",
    "\n",
    "# DROPOUT AND OUTPOUT LAYER\n",
    "#drop_prob = tf.placeholder(tf.float32)\n",
    "#full_one_dropout = tf.nn.dropout(full_layer_one, rate = drop_prob)\n",
    "\n",
    "#keypoints_pred = normal_full_layer(full_one_dropout,30)\n",
    "keypoints_pred = normal_full_layer(full_layer_one,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOSS FUNCTION\n",
    "\n",
    "masked_loss = tf.reduce_mean(tf.square(\n",
    "        tf.boolean_mask(keypoints_pred-keypoints_true, tf.is_finite(keypoints_true) )\n",
    "    ))\n",
    "\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "train = optimizer.minimize(masked_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZER\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints_mean = keypoints_train.mean()\n",
    "\n",
    "# Computing error from the mean in order to have a reference. This is the mark I have to beat. \n",
    "\n",
    "mean_keypoints_mse = ((keypoints_cv-keypoints_mean)**2).sum(axis = 1).mean()\n",
    "mean_keypoints_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================\n",
      "Currently on step 2000\n",
      "Train MSE:  9.305197 \n",
      "\n",
      "CV MSE: 55.872135 \n",
      "\n",
      "=======================================\n",
      "train_losses =  [2527.7842, 44.59074, 32.504192, 24.820585, 47.770237, 22.291718, 17.270071, 20.80441, 18.97765, 16.42134, 14.122369, 21.624735, 13.090026, 10.321592, 18.911974, 23.867962, 9.464927, 9.629934, 13.855001, 10.050628, 9.305197] \n",
      "\n",
      "cv_losses =  [2100.8413, 8259.248, 2222.0679, 703.8109, 262.10687, 94.03295, 78.31416, 42.27904, 59.590115, 76.66046, 67.933, 84.1028, 116.1901, 118.47743, 98.92399, 83.252975, 89.71478, 80.55237, 61.974777, 85.47239, 55.872135]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_steps = 2000\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    #saver.restore(sess, \"./saved_models/keypoints_cnn_0\")\n",
    "    train_losses = []\n",
    "    cv_losses = []\n",
    "    for iteration in range(num_steps+1):\n",
    "        \n",
    "        x_batch, keypoints_batch = next_batch(x_train, keypoints_train, 30)\n",
    "        \n",
    "        _ , train_loss = sess.run([train, masked_loss], \n",
    "                                  feed_dict={x: x_batch, keypoints_true: keypoints_batch,\n",
    "                                             lr:0.001, training:True})\n",
    "        \n",
    "        # PRINT OUT A MESSAGE EVERY 100 STEPS\n",
    "        \n",
    "        #if (iteration%20 == 0) and (iteration >0):\n",
    "            #print(':')\n",
    "        \n",
    "        if iteration%100 == 0:\n",
    "            \n",
    "            cv_loss = sess.run(masked_loss,feed_dict={x:x_cv,keypoints_true:keypoints_cv,\n",
    "                                                      training:False})\n",
    "            \n",
    "            train_losses.append(train_loss)\n",
    "            cv_losses.append(cv_loss)\n",
    "            \n",
    "            # Showing output for tracking progress.\n",
    "            print('=======================================')\n",
    "            print('Currently on step {}'.format(iteration))\n",
    "            print('Train MSE: ', train_loss, '\\n')\n",
    "            print('CV MSE:', cv_loss, '\\n')\n",
    "            \n",
    "            ax.cla()\n",
    "            ax.plot(train_losses[1:], 'r', label = 'Training error')\n",
    "            ax.plot(cv_losses[1:], 'g', label = 'Validation error')\n",
    "            ax.legend()\n",
    "            display(fig)\n",
    "            \n",
    "            print('=======================================')\n",
    "            print('train_losses = ', train_losses, '\\n')\n",
    "            print('cv_losses = ', cv_losses)\n",
    "            clear_output(wait = True)\n",
    "    \n",
    "    # printing final results\n",
    "    \n",
    "    print('=======================================')\n",
    "    print('Currently on step {}'.format(iteration))\n",
    "    print('Train MSE: ', train_loss, '\\n')\n",
    "    print('CV MSE:', cv_loss, '\\n')\n",
    "\n",
    "    ax.cla()\n",
    "    ax.plot(train_losses[1:], 'r', label = 'Training error')\n",
    "    ax.plot(cv_losses[1:], 'g', label = 'Validation error')\n",
    "    ax.legend()\n",
    "    #display(fig)\n",
    "            \n",
    "    print('=======================================')\n",
    "    print('train_losses = ', train_losses, '\\n')\n",
    "    print('cv_losses = ', cv_losses)\n",
    "            \n",
    "    saver.save(sess, \"./saved_models/keypoints_cnn_\" + str(counter) )\n",
    "    #saver.save(sess, \"./saved_models/keypoints_cnn_1\"  )\n",
    "    #counter +=1\n",
    "    #print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Use your Saver instance to restore your saved rnn time series model\n",
    "    saver.restore(sess, \"./saved_models/keypoints_cnn_1\")\n",
    "\n",
    "    # Create a numpy array for your genreative seed from the last 12 months of the \n",
    "    # training set data. Hint: Just use tail(12) and then pass it to an np.array\n",
    "        \n",
    "    predictions = sess.run(keypoints_pred, feed_dict= {x:x_cv, drop_prob:0 })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 3\n",
    "fig, axes = plt.subplots(grid_size, grid_size, gridspec_kw = dict(hspace = .05, wspace = .05), \n",
    "                         figsize=(10,10))\n",
    "\n",
    "selection = np.random.choice(range(len(x_cv)), size = grid_size**2, )\n",
    "\n",
    "mean_x_points = [keypoints_mean[j] for j in range(0,30,2)]\n",
    "mean_y_points = [keypoints_mean[j+1] for j in range(0,30,2)]\n",
    "\n",
    "for i, ax in zip(selection, axes.flat):\n",
    "\n",
    "    ax.axis('off')\n",
    "    # Plotting the faces\n",
    "    ax.imshow(x_cv[i].reshape((96,96)),cmap='gist_gray')\n",
    "\n",
    " # Obtaining keypoints positions. x and y coordinates are even and odd indices respectively. \n",
    "    x_points = [predictions[i][j] for j in range(0,30,2)]\n",
    "    y_points = [predictions[i][j+1] for j in range(0,30,2)]\n",
    "      \n",
    "    #plotting predicted keypoints\n",
    "    ax.plot(x_points, y_points, 'ro', markerfacecolor = 'none')    \n",
    "  \n",
    " # Plotting true keypoints\n",
    "    \n",
    "    x_true = [keypoints_cv.iloc[i][j] for j in range(0,30,2)]\n",
    "    y_true = [keypoints_cv.iloc[i][j+1] for j in range(0,30,2)]\n",
    "    \n",
    "    ax.plot(x_true, y_true, 'y*', markerfacecolor = 'none')    \n",
    "    \n",
    " # Including mean keypoints\n",
    "       \n",
    "    #ax.plot(mean_x_points, mean_y_points, 'b+', markerfacecolor = 'none')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding one more layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLACEHOLDERS\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 9216])\n",
    "keypoints_true = tf.placeholder(tf.float32, [None, 30])\n",
    "lr = tf.placeholder(tf.float32)\n",
    "training = tf.placeholder(tf.bool)\n",
    "drop_rate = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_images = tf.image.per_image_standardization(tf.reshape(x, [-1,96,96,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAYERS\n",
    "\n",
    "convo1 = convolutional_layer(x_images, [8,8,1,32]) # 8 x 8 filter, 1 channel in, 32 channels out. SAME padding.\n",
    "                                            # so output images are also 96 x 96. \n",
    "\n",
    "convo1_pool = max_pool_2by2(convo1)   #output of 24 x 24 x 32\n",
    "\n",
    "convo2 = convolutional_layer(convo1_pool, [4,4,32,64]) # 4x4 filter, 64 outputs. SAME padding.\n",
    "\n",
    "convo2_pool = tf.nn.max_pool(convo2, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME') # 12 x 12 x64\n",
    "\n",
    "convo3 = convolutional_layer(convo2_pool, [2,2,64,128]) # 2x2 filter, 128 outputs. SAME padding.\n",
    "\n",
    "convo3_pool = tf.nn.max_pool(convo3, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME') # 6 x 6 x 128\n",
    "\n",
    "\n",
    "convo3_flat = tf.reshape(convo3_pool,[-1,6*6*128])\n",
    "\n",
    "full_layer_one = tf.nn.relu(normal_full_layer(convo3_flat,1024))\n",
    "\n",
    "# DROPOUT AND OUTPOUT LAYER\n",
    "\n",
    "#full_one_dropout = tf.nn.dropout(full_layer_one, rate = drop_rate)\n",
    "\n",
    "#keypoints_pred = normal_full_layer(full_one_dropout,30)\n",
    "pre_pred_bn = bn_layer(full_layer_one, is_training =training)\n",
    "keypoints_pred = normal_full_layer(pre_pred_bn,30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "# LOSS FUNCTION\n",
    "\n",
    "masked_loss = tf.reduce_mean(tf.square(\n",
    "        tf.boolean_mask(keypoints_pred-keypoints_true, tf.is_finite(keypoints_true) )\n",
    "    ))\n",
    "\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "train = optimizer.minimize(masked_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZER\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-9fab9c3431ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         _ , train_loss = sess.run([train, masked_loss], \n\u001b[1;32m     17\u001b[0m                                   feed_dict={x: x_batch, keypoints_true: keypoints_batch,\n\u001b[0;32m---> 18\u001b[0;31m                                              lr:1, training:True})\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# PRINT OUT A MESSAGE EVERY 100 STEPS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_steps = 5000\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    #saver.restore(sess, \"./saved_models/keypoints_3_lay_cnn0\")\n",
    "    train_losses = []\n",
    "    cv_losses = []\n",
    "    for iteration in range(num_steps+1):\n",
    "        \n",
    "        x_batch, keypoints_batch = next_batch(x_train, keypoints_train, 30)\n",
    "        \n",
    "        _ , train_loss = sess.run([train, masked_loss], \n",
    "                                  feed_dict={x: x_batch, keypoints_true: keypoints_batch,\n",
    "                                             lr:1, training:True})\n",
    "        \n",
    "        # PRINT OUT A MESSAGE EVERY 100 STEPS\n",
    "        \n",
    "        #if (iteration%20 == 0) and (iteration >0):\n",
    "            #print(':')\n",
    "        \n",
    "        if iteration%100 == 0:\n",
    "            \n",
    "            cv_loss = sess.run(masked_loss,feed_dict={x:x_cv,keypoints_true:keypoints_cv,\n",
    "                                                      training:False})\n",
    "            \n",
    "            train_losses.append(train_loss)\n",
    "            cv_losses.append(cv_loss)\n",
    "            \n",
    "            # Showing output for tracking progress.\n",
    "            print('=======================================')\n",
    "            print('Currently on step {}'.format(iteration))\n",
    "            print('Train MSE: ', train_loss, '\\n')\n",
    "            print('CV MSE:', cv_loss, '\\n')\n",
    "            \n",
    "            ax.cla()\n",
    "            ax.plot(train_losses[1:], 'r', label = 'Training error')\n",
    "            ax.plot(cv_losses[1:], 'g', label = 'Validation error')\n",
    "            ax.legend()\n",
    "            display(fig)\n",
    "            \n",
    "            print('=======================================')\n",
    "            print('train_losses = ', train_losses, '\\n')\n",
    "            print('cv_losses = ', cv_losses)\n",
    "            clear_output(wait = True)\n",
    "    \n",
    "    # printing final results\n",
    "    \n",
    "    print('=======================================')\n",
    "    print('Currently on step {}'.format(iteration))\n",
    "    print('Train MSE: ', train_loss, '\\n')\n",
    "    print('CV MSE:', cv_loss, '\\n')\n",
    "\n",
    "    ax.cla()\n",
    "    ax.plot(train_losses[1:], 'r', label = 'Training error')\n",
    "    ax.plot(cv_losses[1:], 'g', label = 'Validation error')\n",
    "    ax.legend()\n",
    "    #display(fig)\n",
    "            \n",
    "    print('=======================================')\n",
    "    print('train_losses = ', train_losses, '\\n')\n",
    "    print('cv_losses = ', cv_losses)\n",
    "            \n",
    "    #saver.save(sess, \"./saved_models/keypoints_3_lay_cnn\" + str(counter) )\n",
    "    #saver.save(sess, \"./saved_models/keypoints_3_lay_cnn_1\"  )\n",
    "    #counter +=1\n",
    "    #print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.387357"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(cv_losses[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
